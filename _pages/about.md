---
layout: archive
title: "About Myself"
# permalink: /about/
permalink: /
author_profile: true
redirect_from:
  - /about/
  - /about.html
  # - /
---

I am currently a second-year Ph.D. candidate in the <strong>Computer Vision and Robotic Perception (CVRP)</strong> Laboratory at <strong> National University of Singapore</strong>, supervised by Prof. [Gim Hee Lee](https://www.comp.nus.edu.sg/~leegh/). Before that, I received my M.Comp. degree from School of Computing, National University of Singapore, and B.Eng. degree from Department of Automation in Tsinghua University, advised by Prof. [Jiwen Lu]([https://scholar.google.com/citations?user=WH0J_34AAAAJ&hl=en](http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/)). I'm broadly interested in 3D Vision, including 3D Scene Representation and Understanding. 


News
======

<div class="mini">
  <p>ğŸ™‡ <strong>[03.2024]</strong> Our paper <a href="https://arxiv.org/pdf/2404.00931">GOV-NeSF</a> is accepted at CVPR 2024!</p>
  <p>ğŸ˜ <strong>[11.2023]</strong> One paper is accepted at WACV 2024 as an oral paper!</p>
  <p>ğŸ˜ <strong>[10.2023]</strong> Our paper GRL is accepted at 3DV 2024 as an oral paper!</p>
  <!-- <div id="hidden-news" style="display: none;">-->
  <p>ğŸš€ <strong>[08.2022]</strong> I am excited to join the <a href="https://www.comp.nus.edu.sg/~leegh/">CVRP lab</a> of SoC, NUS as a PhD student!</p>
  <!-- <p>ğŸ™‡ [03.2021] I joined <b>Alibaba DAMO Academy</b> to work as a computer vision algorithm engineer!</p>
  <p>ğŸš€ [01.2021] I am awarded the <a href="#">Excellent Graduation Thesis</a> in Beihang University!</p>
  <p>ğŸš€ [01.2021] I am awarded the <a href="#">Excellent Graduate</a> in Beihang University!</p>
  <p>ğŸš€ [12.2020] I am awarded the <a href="#">National Scholarship in China</a>!</p>
  <p>ğŸ˜ [09.2020] Our paper <a href="https://arxiv.org/pdf/2009.04247.pdf">BNAS</a> is accepted at IJCV!</p>
  <p>ğŸ˜ [07.2020] Our paper <a href="https://arxiv.org/pdf/2008.00698.pdf">ABanditNAS</a> is accepted at ECCV 2020!</p>
  <p>ğŸ™‡ [06.2020] I joined <b>Alibaba DAMO Academy</b> as a research intern!</p>
  <p>ğŸ˜ [04.2020] Our paper <a href="https://www.ijcai.org/proceedings/2020/0144.pdf">CP-NAS</a> is accepted at IJCAI 2020!</p>
  <p>ğŸ˜ [11.2019] Our paper <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhuo_Cogradient_Descent_for_Bilinear_Optimization_CVPR_2020_paper.pdf">CoGD</a> is accepted at CVPR 2020!</p>
  <p>ğŸ˜ [10.2019] Our paper <a href="https://arxiv.org/pdf/1911.10862v1.pdf">BNAS</a> is accepted at AAAI 2020!</p> -->
    <!-- <p>âœˆï¸ [03.2021] I joined <b>Alibaba DAMO Academy</b> to work as a computer vision algorithm engineer!</p>
    <p>ğŸ† [15.03.2024] Received the .</p> -->
    <!-- ä½ å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤šéšè—çš„æ–°é—»é¡¹ -->
<!--   </div> -->
</div>



Preprints
======
<div style="display: flex; align-items: center; margin-bottom: 40px;">
  <img src="images/FreeSplat.jpg" alt="FreeSplat: Generalizable 3D Gaussian Splatting Towards Free-View Synthesis of Indoor Scenes" style="width: 350px; height: auto; margin-right: 20px;">
  <div>
    <h3 style="margin: 0;">FreeSplat: Generalizable 3D Gaussian Splatting Towards Free-View Synthesis of Indoor Scenes</h3>
    <p style="margin: 5px 0;">
          <strong>Yunsong Wang</strong>,
          <a href="https://tianxinhuang.github.io/">Tianxin Huang</a>,
          <a href="https://hlinchen.github.io/">Hanlin Chen</a>,
          <a href="https://www.comp.nus.edu.sg/~leegh/">Gim Hee Lee</a>
          <br>
      <b><em>arXiv 2024</em></b><br>
      <!-- color: #0073e6; -->
      <!-- <a href="https://hlinchen.github.io/projects/VCR-GauS/" style="text-decoration: none; ">[Project Page]</a> -->
      <a href="https://arxiv.org/pdf/2405.17958" style="text-decoration: none;">[PDF]</a> 
      <a href="https://github.com/wangys16/FreeSplat" style="text-decoration: none;">[Code]</a>
      <!-- <a href="https://video.com" style="text-decoration: none;">Video</a> / -->
      <!-- <a class="more-link" href="https://github.com/HeliosZhao/Animate124" target="_blank"><img alt="GitHub stars" align="right"
        src="https://img.shields.io/github/stars/HeliosZhao/Animate124?style=social"></a> -->
    </p>
    <!-- <p style="margin: 5px 0;">
      The first work to animate a single in-the-wild image into 3D video through textual motion descriptions.
    </p> -->
    <div style="display: flex; align-items: center; margin-top: 10px;">
      <a href="https://github.com/yourrepo" style="display: flex; align-items: center; text-decoration: none; color: #000;">
      </a>
    </div>
  </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 40px;">
  <img src="images/VCR-GauS.jpg" alt="VCR-GauS: View Consistent Depth-Normal Regularizer for Gaussian Surface Reconstruction" style="width: 350px; height: auto; margin-right: 20px;">
  <div>
    <h3 style="margin: 0;">VCR-GauS: View Consistent Depth-Normal Regularizer for Gaussian Surface Reconstruction</h3>
    <p style="margin: 5px 0;">
          <a href="https://hlinchen.github.io/">Hanlin Chen</a>,
          <a href="https://weify627.github.io/">Fangyin Wei</a>,
          <a href="https://chaneyddtt.github.io/">Chen Li</a>,
          <a href="https://tianxinhuang.github.io/">Tianxin Huang</a>,
          <strong>Yunsong Wang</strong>,
          <a href="https://www.comp.nus.edu.sg/~leegh/">Gim Hee Lee</a>
          <br>
      <b><em>arXiv 2024</em></b><br>
      <!-- color: #0073e6; -->
      <a href="https://hlinchen.github.io/projects/VCR-GauS/" style="text-decoration: none; ">[Project Page]</a>
      <a href="https://arxiv.org/pdf/2406.05774" style="text-decoration: none;">[PDF]</a> 
      <a href="https://github.com/HLinChen/VCR-GauS" style="text-decoration: none;">[Code]</a>
      <!-- <a href="https://video.com" style="text-decoration: none;">Video</a> / -->
      <!-- <a class="more-link" href="https://github.com/HeliosZhao/Animate124" target="_blank"><img alt="GitHub stars" align="right"
        src="https://img.shields.io/github/stars/HeliosZhao/Animate124?style=social"></a> -->
    </p>
    <!-- <p style="margin: 5px 0;">
      The first work to animate a single in-the-wild image into 3D video through textual motion descriptions.
    </p> -->
    <div style="display: flex; align-items: center; margin-top: 10px;">
      <a href="https://github.com/yourrepo" style="display: flex; align-items: center; text-decoration: none; color: #000;">
      </a>
    </div>
  </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 40px;">
  <img src="images/NeuSG.jpg" alt="NeuSG: Neural implicit surface reconstruction with 3d gaussian splatting guidance" style="width: 350px; height: auto; margin-right: 20px;">

  <div>
    <h3 style="margin: 0;">NeuSG: Neural implicit surface reconstruction with 3d gaussian splatting guidance</h3>
    <p style="margin: 5px 0;">
          <a href="https://hlinchen.github.io/">Hanlin Chen</a>,
          <a href="https://chaneyddtt.github.io/">Chen Li</a>,
          <strong>Yunsong Wang</strong>,
          <a href="https://www.comp.nus.edu.sg/~leegh/">Gim Hee Lee</a>
          <br>
      <b><em>arXiv 2023</em></b><br>
      <!-- <a href="https://projectpage.com" style="text-decoration: none;">[Project Page]</a> -->
      <a href="https://arxiv.org/pdf/2312.00846" style="text-decoration: none;">[PDF]</a>
      <!-- <a href="https://github.com/wangys16/GOV-NeSF" style="text-decoration: none;">[Code]</a> -->
      <!-- <a href="https://video.com" style="text-decoration: none;">[Video]</a> -->
      <!-- <a class="more-link" href="https://github.com/HeliosZhao/Animate124" target="_blank"><img alt="GitHub stars" align="right"
        src="https://img.shields.io/github/stars/HeliosZhao/Animate124?style=social"></a> -->
    </p>
    <!-- <p style="margin: 5px 0;">
      The first work to animate a single in-the-wild image into 3D video through textual motion descriptions.
    </p> -->
    <div style="display: flex; align-items: center; margin-top: 10px;">
      <a href="https://github.com/yourrepo" style="display: flex; align-items: center; text-decoration: none; color: #000;">
      </a>
    </div>
  </div>
</div>

Publications
======

<div style="display: flex; align-items: center; margin-bottom: 40px;">
  <img src="images/GOV-NeSF.jpg" alt="GOV-NeSF: Generalizable Open-Vocabulary Neural Semantic Fields" style="width: 350px; height: auto; margin-right: 20px;">

  <div>
    <h3 style="margin: 0;">GOV-NeSF: Generalizable Open-Vocabulary Neural Semantic Fields</h3>
    <p style="margin: 5px 0;">
          <strong>Yunsong Wang</strong>,
          <a href="https://hlinchen.github.io/">Hanlin Chen</a>,
          <a href="https://www.comp.nus.edu.sg/~leegh/">Gim Hee Lee</a>
          <br>
      <b><em>CVPR 2024</em></b><br>
      <!-- color: #0073e6; -->
      <!-- <a href="https://projectpage.com" style="text-decoration: none; ">Project Page</a> / -->
      <a href="https://arxiv.org/pdf/2404.00931" style="text-decoration: none;">[PDF]</a> 
      <a href="https://github.com/wangys16/GOV-NeSF" style="text-decoration: none;">[Code]</a>
      <!-- <a href="https://video.com" style="text-decoration: none;">Video</a> / -->
      <!-- <a class="more-link" href="https://github.com/HeliosZhao/Animate124" target="_blank"><img alt="GitHub stars" align="right"
        src="https://img.shields.io/github/stars/HeliosZhao/Animate124?style=social"></a> -->
    </p>
    <!-- <p style="margin: 5px 0;">
      The first work to animate a single in-the-wild image into 3D video through textual motion descriptions.
    </p> -->
    <div style="display: flex; align-items: center; margin-top: 10px;">
      <a href="https://github.com/yourrepo" style="display: flex; align-items: center; text-decoration: none; color: #000;">
      </a>
    </div>
  </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 40px;">
  <img src="images/rethink.pdf" alt="Rethinking Visibility in Human Pose Estimation: Occluded Pose Reasoning via Transformers" style="width: 350px; height: auto; margin-right: 20px;">

  <div>
    <h3 style="margin: 0;">Rethinking Visibility in Human Pose Estimation: Occluded Pose Reasoning via Transformer</h3>
    <p style="margin: 5px 0;">
      <a href="https://pengzhansun.github.io/">Pengzhan Sun</a>,
      <a href="https://www.comp.nus.edu.sg/~keruigu/">Kerui Gu</a>,
      <strong>Yunsong Wang</strong>,
      <a href="=https://mu4yang.com">Linlin Yang</a>,
      <a href="https://www.comp.nus.edu.sg/~ayao/">Angela Yao</a>
      <br>
      <b><em>WACV 2024 (<i style="color:#e74d3c"> Oral Presentation </i>)</em></b><br>
      <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Sun_Rethinking_Visibility_in_Human_Pose_Estimation_Occluded_Pose_Reasoning_via_WACV_2024_paper.pdf" style="text-decoration: none;">[PDF]</a>
      <a href="https://github.com/pengzhansun/Occluded-Pose-Reasoning" style="text-decoration: none;">[Code]</a>
    </p>
  </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 40px;">
  <img src="images/GRL.pdf" alt="Enhancing Generalizability of Representation Learning for Data-Efficient 3D Scene Understanding" style="width: 350px; height: auto; margin-right: 20px;">

  <div>
    <h3 style="margin: 0;">Enhancing Generalizability of Representation Learning for Data-Efficient 3D Scene Understanding</h3>
    <p style="margin: 5px 0;">
      <strong>Yunsong Wang</strong>,
      <a href="https://na-z.github.io">Na Zhao</a>,
      <a href="https://www.comp.nus.edu.sg/~leegh/">Gim Hee Lee</a>
      <br>
      <b><em>3DV 2024 (<i style="color:#e74d3c"> Oral Presentation </i>)</em></b><br>
      <a href="https://arxiv.org/abs/2406.11283" style="text-decoration: none;">[PDF]</a>
      <!--<a href="https://github.com/HLinChen/GNeSF" style="text-decoration: none;">[Code]</a>-->
    </p>
  </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 40px;">
  <img src="images/ISL.png" alt="Instance Similarity Learning for Unsupervised Feature Representation" style="width: 350px; height: auto; margin-right: 20px;">

  <div>
    <h3 style="margin: 0;">Instance Similarity Learning for Unsupervised Feature Representation</h3>
    <p style="margin: 5px 0;">
      <a href="https://ziweiwangthu.github.io">Ziwei Wang</a>,
      <strong>Yunsong Wang</strong>,
      <a href="https://wuziyi616.github.io">Ziyi Wu</a>,
      <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Jiwen Lu</a>,
      <a href="https://scholar.google.com/citations?user=6a79aPwAAAAJ&hl=en&authuser=1">Jie Zhou</a>
      <br>
      <b><em>ICCV 2021</em></b><br>
      <a href="https://arxiv.org/abs/2108.02721" style="text-decoration: none;">[PDF]</a>
      <a href="https://github.com/ZiweiWangTHU/ISL" style="text-decoration: none;">[Code]</a>
    </p>
  </div>
</div>

